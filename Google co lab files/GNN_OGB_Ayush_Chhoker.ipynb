{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing GNNs on OGB arXiv Dataset\n",
        "\n",
        "This notebook experiments with different GNN architectures on the OGB arXiv citation network.\n",
        "\n",
        "**Dataset:** 169k CS papers, 40 subject areas, 1.17M citations\n",
        "\n",
        "**Models:** GAT, GCN, GraphSAGE\n",
        "\n",
        "The goal is to classify papers into research topics based on their citation patterns and features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation\n",
        "\n",
        "Installing necessary packages - this might take a couple minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q ogb\n",
        "!pip install -q matplotlib seaborn pandas numpy scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GCNConv, SAGEConv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# GPU check\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Running on: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading OGB arXiv Dataset\n",
        "\n",
        "This dataset is pretty large so downloading might take a bit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix for PyTorch 2.6+ compatibility issue\n",
        "import torch.serialization\n",
        "from torch_geometric.data.data import DataEdgeAttr\n",
        "\n",
        "# Monkey patch to handle the deprecation\n",
        "if not hasattr(torch.serialization, 'add_safe_globals'):\n",
        "    torch.serialization.add_safe_globals = lambda x: None\n",
        "torch.serialization.add_safe_globals([DataEdgeAttr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ogb.nodeproppred import PygNodePropPredDataset\n",
        "\n",
        "print(\"Downloading OGB arXiv dataset...\")\n",
        "dataset = PygNodePropPredDataset(name='ogbn-arxiv', root='/tmp/ogb')\n",
        "data = dataset[0]\n",
        "split_idx = dataset.get_idx_split()\n",
        "\n",
        "# Add train/val/test masks to data object\n",
        "data.train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.train_mask[split_idx['train']] = True\n",
        "\n",
        "data.val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.val_mask[split_idx['valid']] = True\n",
        "\n",
        "data.test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
        "data.test_mask[split_idx['test']] = True\n",
        "\n",
        "# Flatten labels\n",
        "data.y = data.y.squeeze(1)\n",
        "\n",
        "print(f\"\\nDataset loaded!\")\n",
        "print(f\"  Nodes: {data.num_nodes:,}\")\n",
        "print(f\"  Edges: {data.num_edges:,}\")\n",
        "print(f\"  Features: {data.num_features}\")\n",
        "print(f\"  Classes: {dataset.num_classes}\")\n",
        "print(f\"  Train: {split_idx['train'].shape[0]:,}\")\n",
        "print(f\"  Val: {split_idx['valid'].shape[0]:,}\")\n",
        "print(f\"  Test: {split_idx['test'].shape[0]:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Definitions\n",
        "\n",
        "Defining the three GNN architectures we'll compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GAT(nn.Module):\n",
        "    \"\"\"Graph Attention Network\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=dropout)\n",
        "        self.dropout = dropout\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    \"\"\"Graph Convolutional Network\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    \"\"\"GraphSAGE with neighborhood sampling\"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "    \n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "print(\"Models ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n",
        "\n",
        "Standard training loop with early stopping based on validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, data, model_name, epochs=200, lr=0.01, weight_decay=5e-4, patience=40):\n",
        "    \"\"\"\n",
        "    Train a GNN model with early stopping\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    data = data.to(device)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.NLLLoss()\n",
        "    \n",
        "    best_val_acc = 0\n",
        "    best_model_state = None\n",
        "    patience_counter = 0\n",
        "    \n",
        "    train_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index)\n",
        "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            out = model(data.x, data.edge_index)\n",
        "            pred = out.argmax(dim=1)\n",
        "            val_correct = (pred[data.val_mask] == data.y[data.val_mask]).sum().item()\n",
        "            val_acc = val_correct / data.val_mask.sum().item()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        # Track best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        \n",
        "        if epoch % 20 == 0:\n",
        "            print(f\"Epoch {epoch:3d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f} | Best: {best_val_acc:.4f}\")\n",
        "        \n",
        "        # Early stopping\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch}\")\n",
        "            break\n",
        "    \n",
        "    # Restore best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
        "    \n",
        "    return model, train_losses, val_accs\n",
        "\n",
        "def evaluate_model(model, data):\n",
        "    \"\"\"\n",
        "    Evaluate model on test set\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out.argmax(dim=1)\n",
        "        \n",
        "        # Test accuracy\n",
        "        test_correct = (pred[data.test_mask] == data.y[data.test_mask]).sum().item()\n",
        "        test_acc = test_correct / data.test_mask.sum().item()\n",
        "        \n",
        "        # Additional metrics\n",
        "        y_true = data.y[data.test_mask].cpu().numpy()\n",
        "        y_pred = pred[data.test_mask].cpu().numpy()\n",
        "        \n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, average='weighted', zero_division=0\n",
        "        )\n",
        "    \n",
        "    return test_acc, precision, recall, f1, y_true, y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training All Models\n",
        "\n",
        "Now let's train all three models and compare their performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GAT (Graph Attention Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gat = GAT(data.num_features, 256, dataset.num_classes, heads=4, dropout=0.5)\n",
        "gat_model, gat_losses, gat_val_accs = train_model(\n",
        "    gat, data, 'GAT', \n",
        "    epochs=200, \n",
        "    lr=0.005, \n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "gat_test_acc, gat_precision, gat_recall, gat_f1, gat_y_true, gat_y_pred = evaluate_model(gat_model, data)\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"GAT Test Results:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Accuracy:  {gat_test_acc:.4f}\")\n",
        "print(f\"Precision: {gat_precision:.4f}\")\n",
        "print(f\"Recall:    {gat_recall:.4f}\")\n",
        "print(f\"F1 Score:  {gat_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GCN (Graph Convolutional Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gcn = GCN(data.num_features, 256, dataset.num_classes, dropout=0.5)\n",
        "gcn_model, gcn_losses, gcn_val_accs = train_model(\n",
        "    gcn, data, 'GCN', \n",
        "    epochs=200, \n",
        "    lr=0.01, \n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "gcn_test_acc, gcn_precision, gcn_recall, gcn_f1, gcn_y_true, gcn_y_pred = evaluate_model(gcn_model, data)\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"GCN Test Results:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Accuracy:  {gcn_test_acc:.4f}\")\n",
        "print(f\"Precision: {gcn_precision:.4f}\")\n",
        "print(f\"Recall:    {gcn_recall:.4f}\")\n",
        "print(f\"F1 Score:  {gcn_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GraphSAGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sage = GraphSAGE(data.num_features, 256, dataset.num_classes, dropout=0.5)\n",
        "sage_model, sage_losses, sage_val_accs = train_model(\n",
        "    sage, data, 'GraphSAGE', \n",
        "    epochs=200, \n",
        "    lr=0.01, \n",
        "    weight_decay=5e-4\n",
        ")\n",
        "\n",
        "sage_test_acc, sage_precision, sage_recall, sage_f1, sage_y_true, sage_y_pred = evaluate_model(sage_model, data)\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"GraphSAGE Test Results:\")\n",
        "print(f\"{'='*50}\")\n",
        "print(f\"Accuracy:  {sage_test_acc:.4f}\")\n",
        "print(f\"Precision: {sage_precision:.4f}\")\n",
        "print(f\"Recall:    {sage_recall:.4f}\")\n",
        "print(f\"F1 Score:  {sage_f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Comparison\n",
        "\n",
        "Let's put all the results together and see which model won"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "results_df = pd.DataFrame({\n",
        "    'Model': ['GAT', 'GCN', 'GraphSAGE'],\n",
        "    'Test Accuracy': [gat_test_acc, gcn_test_acc, sage_test_acc],\n",
        "    'Precision': [gat_precision, gcn_precision, sage_precision],\n",
        "    'Recall': [gat_recall, gcn_recall, sage_recall],\n",
        "    'F1 Score': [gat_f1, gcn_f1, sage_f1]\n",
        "})\n",
        "\n",
        "# Sort by test accuracy\n",
        "results_df = results_df.sort_values('Test Accuracy', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL RESULTS - OGB ARXIV DATASET\")\n",
        "print(\"=\"*70)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training dynamics\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Training loss\n",
        "axes[0].plot(gat_losses, label='GAT', linewidth=2, alpha=0.7)\n",
        "axes[0].plot(gcn_losses, label='GCN', linewidth=2, alpha=0.7)\n",
        "axes[0].plot(sage_losses, label='GraphSAGE', linewidth=2, alpha=0.7)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Training Loss', fontsize=12)\n",
        "axes[0].set_title('Training Loss Curves', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(fontsize=11)\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Validation accuracy\n",
        "axes[1].plot(gat_val_accs, label='GAT', linewidth=2, alpha=0.7)\n",
        "axes[1].plot(gcn_val_accs, label='GCN', linewidth=2, alpha=0.7)\n",
        "axes[1].plot(sage_val_accs, label='GraphSAGE', linewidth=2, alpha=0.7)\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Validation Accuracy', fontsize=12)\n",
        "axes[1].set_title('Validation Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(fontsize=11)\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar chart comparing models\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "x = np.arange(len(results_df))\n",
        "width = 0.2\n",
        "\n",
        "ax.bar(x - 1.5*width, results_df['Test Accuracy'], width, label='Accuracy', alpha=0.8)\n",
        "ax.bar(x - 0.5*width, results_df['Precision'], width, label='Precision', alpha=0.8)\n",
        "ax.bar(x + 0.5*width, results_df['Recall'], width, label='Recall', alpha=0.8)\n",
        "ax.bar(x + 1.5*width, results_df['F1 Score'], width, label='F1', alpha=0.8)\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=12)\n",
        "ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(results_df['Model'])\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Results\n",
        "\n",
        "Let's save the trained models and results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save everything\n",
        "torch.save({\n",
        "    'gat_state': gat_model.state_dict(),\n",
        "    'gcn_state': gcn_model.state_dict(),\n",
        "    'sage_state': sage_model.state_dict(),\n",
        "    'results': results_df.to_dict(),\n",
        "    'dataset_info': {\n",
        "        'num_features': data.num_features,\n",
        "        'num_classes': dataset.num_classes,\n",
        "        'num_nodes': data.num_nodes,\n",
        "        'num_edges': data.num_edges\n",
        "    }\n",
        "}, 'ogb_arxiv_models.pt')\n",
        "\n",
        "print(\"\\nAll models and results saved to 'ogb_arxiv_models.pt'\")\n",
        "print(\"\\nDone! \ud83c\udf89\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}